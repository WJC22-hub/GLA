from transformers import T5Tokenizer
from torchvision import transforms
import json
import os
import time
from torch.utils.data import DataLoader, ConcatDataset, Subset
import torch
import torch.nn as nn
import argparse
from modules.multi_frame_dataset import BackdoorMultiFrameDataset
from modules.multi_frame_model import print_trainable_parameters, DriveVLMT5
import matplotlib.pyplot as plt
import pandas as pd
from copy import deepcopy
from tqdm import tqdm
import random

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')


def save_model(model_state_dict, model_name):
    """ä¿å­˜æ¨¡å‹"""
    path = os.path.join('multi_frame_results', timestr, model_name + '.pth')
    torch.save(model_state_dict, path)
    print(f'æ¨¡å‹å·²ä¿å­˜: {path}')


def val_model(dloader, val_model):
    """è®¡ç®—éªŒè¯æŸå¤±"""
    val_model.eval()
    total_loss = 0
    loss_fct = nn.CrossEntropyLoss(reduction='mean')
    
    with torch.no_grad():
        for inputs, imgs, labels in tqdm(dloader, desc="éªŒè¯ä¸­"):
            outputs = val_model(inputs, imgs, labels)
            logits = outputs.logits
            
            loss = loss_fct(
                logits.view(-1, logits.shape[-1]),
                labels.view(-1)
            )
            total_loss += loss.item()
    
    avg_loss = total_loss / len(dloader)
    return avg_loss


def calculate_mixed_metrics(poison_dloader, clean_dloader, eval_model, target_prefix="advertise", debug=False):
    """
    è®¡ç®—æ··åˆè®­ç»ƒçš„å…³é”®æŒ‡æ ‡:
    1. ASR (Attack Success Rate): æ±¡æŸ“æ ·æœ¬ä¸­æˆåŠŸè§¦å‘ç›®æ ‡å‰ç¼€çš„æ¯”ä¾‹
    2. FPR (False Positive Rate): å¹²å‡€æ ·æœ¬ä¸­è¯¯è§¦å‘ç›®æ ‡å‰ç¼€çš„æ¯”ä¾‹
    """
    eval_model.eval()
    
    # æ±¡æŸ“æ ·æœ¬ç»Ÿè®¡
    poison_total = 0
    poison_success = 0
    
    # å¹²å‡€æ ·æœ¬ç»Ÿè®¡
    clean_total = 0
    clean_false_trigger = 0
    
    debug_outputs = {'poison': [], 'clean': []}
    
    with torch.no_grad():
        # è¯„ä¼°æ±¡æŸ“æ ·æœ¬ - è®¡ç®—ASR
        print("\nğŸ“Š è¯„ä¼°æ±¡æŸ“æ ·æœ¬ (ASR)...")
        for inputs, imgs, labels in tqdm(poison_dloader, desc="æ±¡æŸ“æ ·æœ¬"):
            outputs = eval_model.generate(inputs, imgs)
            text_outputs = [processor.decode(output, skip_special_tokens=True) 
                          for output in outputs]
            
            label_texts = [processor.decode(label[label != -100], skip_special_tokens=True) 
                         for label in labels]
            
            for idx, text_output in enumerate(text_outputs):
                poison_total += 1
                output_clean = text_output.strip().lower()
                prefix_clean = target_prefix.lower()
                
                is_triggered = output_clean.startswith(prefix_clean)
                if is_triggered:
                    poison_success += 1
                
                if debug and len(debug_outputs['poison']) < 5:
                    debug_outputs['poison'].append({
                        'generated': text_output,
                        'expected': label_texts[idx] if idx < len(label_texts) else "N/A",
                        'triggered': is_triggered
                    })
        
        # è¯„ä¼°å¹²å‡€æ ·æœ¬ - è®¡ç®—FPR
        print("\nğŸ“Š è¯„ä¼°å¹²å‡€æ ·æœ¬ (FPR)...")
        for inputs, imgs, labels in tqdm(clean_dloader, desc="å¹²å‡€æ ·æœ¬"):
            outputs = eval_model.generate(inputs, imgs)
            text_outputs = [processor.decode(output, skip_special_tokens=True) 
                          for output in outputs]
            
            label_texts = [processor.decode(label[label != -100], skip_special_tokens=True) 
                         for label in labels]
            
            for idx, text_output in enumerate(text_outputs):
                clean_total += 1
                output_clean = text_output.strip().lower()
                prefix_clean = target_prefix.lower()
                
                is_false_trigger = output_clean.startswith(prefix_clean)
                if is_false_trigger:
                    clean_false_trigger += 1
                
                if debug and len(debug_outputs['clean']) < 5:
                    debug_outputs['clean'].append({
                        'generated': text_output,
                        'expected': label_texts[idx] if idx < len(label_texts) else "N/A",
                        'false_triggered': is_false_trigger
                    })
    
    # è®¡ç®—æŒ‡æ ‡
    asr = (poison_success / poison_total * 100) if poison_total > 0 else 0.0
    fpr = (clean_false_trigger / clean_total * 100) if clean_total > 0 else 0.0
    
    # Debugè¾“å‡º
    if debug:
        print(f"\n{'='*80}")
        print(f"ğŸ” æ··åˆè®­ç»ƒæŒ‡æ ‡è¯¦ç»†è°ƒè¯•ä¿¡æ¯")
        print(f"{'='*80}")
        print(f"ç›®æ ‡å‰ç¼€: '{target_prefix}'")
        print(f"\nã€æ±¡æŸ“æ ·æœ¬ç¤ºä¾‹ã€‘(å‰{len(debug_outputs['poison'])}ä¸ª):")
        for i, sample in enumerate(debug_outputs['poison'], 1):
            print(f"  æ ·æœ¬ {i}:")
            print(f"    æœŸæœ›: {sample['expected']}")
            print(f"    ç”Ÿæˆ: {sample['generated']}")
            print(f"    è§¦å‘: {'âœ“' if sample['triggered'] else 'âœ—'}")
        
        print(f"\nã€å¹²å‡€æ ·æœ¬ç¤ºä¾‹ã€‘(å‰{len(debug_outputs['clean'])}ä¸ª):")
        for i, sample in enumerate(debug_outputs['clean'], 1):
            print(f"  æ ·æœ¬ {i}:")
            print(f"    æœŸæœ›: {sample['expected']}")
            print(f"    ç”Ÿæˆ: {sample['generated']}")
            print(f"    è¯¯è§¦: {'âœ“ (é—®é¢˜!)' if sample['false_triggered'] else 'âœ— (æ­£å¸¸)'}")
        
        print(f"\n{'='*80}")
        print(f"ğŸ“Š ç»Ÿè®¡ç»“æœ:")
        print(f"  æ±¡æŸ“æ ·æœ¬: {poison_success}/{poison_total} è§¦å‘ â†’ ASR = {asr:.2f}%")
        print(f"  å¹²å‡€æ ·æœ¬: {clean_false_trigger}/{clean_total} è¯¯è§¦ â†’ FPR = {fpr:.2f}%")
        print(f"{'='*80}\n")
    
    return {
        'asr': asr,
        'fpr': fpr,
        'poison_success': poison_success,
        'poison_total': poison_total,
        'clean_false_trigger': clean_false_trigger,
        'clean_total': clean_total
    }


def save_stats(train_loss, val_loss, metrics_history, test_metrics, epochs, lr):
    """ä¿å­˜è®­ç»ƒç»Ÿè®¡ï¼ˆæ›´æ–°ç‰ˆï¼ŒåŒ…å«æµ‹è¯•æŒ‡æ ‡å’Œæ±¡æŸ“æ ·æœ¬æ•°é‡ï¼‰"""
    stats_dict = {
        'losses': losses,
        'val_losses': val_losses,
        'asr_history': [m['asr'] for m in metrics_history],
        'fpr_history': [m['fpr'] for m in metrics_history],
        'min_train_loss': train_loss,
        'min_val_loss': val_loss,
        'best_val_asr': max([m['asr'] for m in metrics_history]),
        'final_val_metrics': metrics_history[-1] if metrics_history else {},
        'test_metrics': test_metrics,
        'epochs': epochs,
        'learning_rate': lr,
        'LM': config.lm,
        'LoRA': config.lora,
        'Clean_Dataset': config.clean_data_dir,
        'Poison_Dataset': config.poison_data_dir,
        'Poison_Sample_Num': config.poison_sample_num,  # æ–°å¢
        'Actual_Poison_Train_Num': actual_poison_train_num,  # æ–°å¢
        'Target_Prefix': config.target_prefix,
    }
    
    with open(os.path.join('multi_frame_results', timestr, 'stats.json'), 'w') as f:
        json.dump(stats_dict, f, indent=2)


def plot_metrics(training_loss, val_loss, metrics_hist, test_metrics=None):
    """
    ç»˜åˆ¶è®­ç»ƒæŒ‡æ ‡ï¼ˆåŒ…å«æµ‹è¯•ç»“æœï¼‰
    
    Args:
        training_loss: è®­ç»ƒæŸå¤±åˆ—è¡¨
        val_loss: éªŒè¯æŸå¤±åˆ—è¡¨
        metrics_hist: éªŒè¯æŒ‡æ ‡å†å² [{'asr': ..., 'fpr': ...}, ...]
        test_metrics: æµ‹è¯•æŒ‡æ ‡ {'asr': ..., 'fpr': ..., 'poison_success': ..., ...}
    """
    num_epochs = len(training_loss)
    asr_hist = [m['asr'] for m in metrics_hist]
    fpr_hist = [m['fpr'] for m in metrics_hist]
    
    fig, axes = plt.subplots(1, 3, figsize=(18, 5))
    
    # ==================== å›¾1: æŸå¤±æ›²çº¿ ====================
    axes[0].plot(range(1, num_epochs + 1), training_loss, label='Training Loss', 
                marker='o', linewidth=2, color='#1f77b4')
    axes[0].plot(range(1, num_epochs + 1), val_loss, label='Validation Loss', 
                marker='s', linewidth=2, color='#ff7f0e')
    axes[0].set_title('Training and Validation Loss', fontsize=14, fontweight='bold')
    axes[0].set_xlabel('Epoch', fontsize=12)
    axes[0].set_ylabel('Loss', fontsize=12)
    axes[0].legend(fontsize=11)
    axes[0].grid(True, alpha=0.3)
    axes[0].set_xticks(range(1, num_epochs + 1))
    
    # ==================== å›¾2: ASRæ›²çº¿ + æµ‹è¯•ç»“æœ ====================
    # éªŒè¯é›†ASRæ›²çº¿
    axes[1].plot(range(1, num_epochs + 1), asr_hist, label='Validation ASR', 
                marker='o', color='red', linewidth=2.5)
    
    # ç›®æ ‡çº¿ï¼ˆ100%ï¼‰
    axes[1].axhline(y=100, color='green', linestyle='--', alpha=0.5, 
                   linewidth=1.5, label='Target (100%)')
    
    # æ·»åŠ æµ‹è¯•ç»“æœæ¨ªçº¿
    if test_metrics and 'asr' in test_metrics:
        test_asr = test_metrics['asr']
        axes[1].axhline(y=test_asr, color='purple', linestyle=':', 
                       linewidth=3, alpha=0.8, 
                       label=f'Test ASR: {test_asr:.1f}%')
        
        # åœ¨æ¨ªçº¿å³ä¾§æ·»åŠ æ•°å€¼æ ‡æ³¨
        axes[1].text(num_epochs + 0.3, test_asr, 
                    f'{test_asr:.1f}%\n({test_metrics["poison_success"]}/{test_metrics["poison_total"]})',
                    fontsize=10, color='purple', fontweight='bold',
                    verticalalignment='center')
    
    axes[1].set_title('Attack Success Rate (ASR)', fontsize=14, fontweight='bold')
    axes[1].set_xlabel('Epoch', fontsize=12)
    axes[1].set_ylabel('ASR (%)', fontsize=12)
    axes[1].legend(fontsize=11, loc='lower right')
    axes[1].grid(True, alpha=0.3)
    axes[1].set_ylim([0, 105])
    axes[1].set_xticks(range(1, num_epochs + 1))
    
    # ==================== å›¾3: FPRæ›²çº¿ + æµ‹è¯•ç»“æœ ====================
    # éªŒè¯é›†FPRæ›²çº¿
    axes[2].plot(range(1, num_epochs + 1), fpr_hist, label='Validation FPR', 
                marker='s', color='orange', linewidth=2.5)
    
    # ç†æƒ³çº¿ï¼ˆ0%ï¼‰
    axes[2].axhline(y=0, color='green', linestyle='--', alpha=0.5, 
                   linewidth=1.5, label='Ideal (0%)')
    
    # æ·»åŠ æµ‹è¯•ç»“æœæ¨ªçº¿
    if test_metrics and 'fpr' in test_metrics:
        test_fpr = test_metrics['fpr']
        axes[2].axhline(y=test_fpr, color='brown', linestyle=':', 
                       linewidth=3, alpha=0.8, 
                       label=f'Test FPR: {test_fpr:.1f}%')
        
        # åœ¨æ¨ªçº¿å³ä¾§æ·»åŠ æ•°å€¼æ ‡æ³¨
        axes[2].text(num_epochs + 0.3, test_fpr, 
                    f'{test_fpr:.1f}%\n({test_metrics["clean_false_trigger"]}/{test_metrics["clean_total"]})',
                    fontsize=10, color='brown', fontweight='bold',
                    verticalalignment='center')
    
    axes[2].set_title('False Positive Rate (FPR)', fontsize=14, fontweight='bold')
    axes[2].set_xlabel('Epoch', fontsize=12)
    axes[2].set_ylabel('FPR (%)', fontsize=12)
    axes[2].legend(fontsize=11, loc='upper right')
    axes[2].grid(True, alpha=0.3)
    axes[2].set_xticks(range(1, num_epochs + 1))
    
    # åŠ¨æ€è°ƒæ•´FPRçš„Yè½´èŒƒå›´
    if test_metrics and 'fpr' in test_metrics:
        max_fpr_val = max(max(fpr_hist), test_metrics['fpr'])
        axes[2].set_ylim([0, max(max_fpr_val * 1.3, 5)])
    
    plt.tight_layout()
    plt.savefig(os.path.join('multi_frame_results', timestr, 'metrics.png'), 
               dpi=150, bbox_inches='tight')
    plt.close()
    
    print(f"âœ“ æŒ‡æ ‡å›¾è¡¨å·²ä¿å­˜ï¼ˆåŒ…å«æµ‹è¯•ç»“æœï¼‰")


def custom_train(train_loss, val_loss, best_asr, best_model, epochs, learning_rate):
    """æ··åˆè®­ç»ƒå¾ªç¯"""
    
    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=config.weight_decay)
    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(
        optimizer, T_max=config.epochs, eta_min=learning_rate * 0.01
    )
    
    print(f"\n{'='*70}")
    print(f"ğŸ¯ å¼€å§‹æ··åˆè®­ç»ƒ (å¹²å‡€ + æ±¡æŸ“)")
    print(f"{'='*70}\n")
    
    for epoch in range(epochs, config.epochs):
        print(f'\n{"="*70}')
        print(f'EPOCH {epoch + 1}/{config.epochs}')
        print(f'{"="*70}')
        
        model.train()
        epoch_loss = 0
        batch_count = 0
        
        progress_bar = tqdm(train_dataloader, desc=f"è®­ç»ƒ Epoch {epoch+1}")
        for step, (inputs, imgs, labels) in enumerate(progress_bar):
            outputs = model(inputs, imgs, labels)
            loss = outputs.loss
            epoch_loss += loss.item()
            batch_count += 1
            
            progress_bar.set_postfix({'loss': f'{loss.item():.4f}'})
            
            if step % 50 == 0 and step > 0:
                avg_loss = epoch_loss / batch_count
                print(f'\n  [Step {step}/{len(train_dataloader)}] '
                      f'å½“å‰Loss: {loss.item():.4f}, å¹³å‡Loss: {avg_loss:.4f}')
            
            loss.backward()
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
            optimizer.step()
            optimizer.zero_grad()
        
        epoch_train_loss = epoch_loss / len(train_dataloader)
        losses.append(epoch_train_loss)
        
        # éªŒè¯æŸå¤±
        epoch_val_loss = val_model(val_dataloader, model)
        val_losses.append(epoch_val_loss)
        
        # è®¡ç®—æ··åˆæŒ‡æ ‡
        debug_mode = (epoch == 0)
        metrics = calculate_mixed_metrics(
            val_poison_dataloader, val_clean_dataloader, 
            model, config.target_prefix, debug=debug_mode
        )
        metrics_history.append(metrics)
        
        # æ›´æ–°æœ€ä½³æŒ‡æ ‡
        if not val_loss or epoch_val_loss < val_loss:
            val_loss = epoch_val_loss
        
        if not train_loss or epoch_train_loss < train_loss:
            train_loss = epoch_train_loss
        
        if not best_asr or metrics['asr'] > best_asr:
            best_asr = metrics['asr']
            best_model = deepcopy(model.state_dict())
            print(f'\nğŸ¯ æ–°æœ€ä½³ASR: {best_asr:.2f}%')
            save_model(best_model, 'best_model')
        
        scheduler.step()
        current_lr = scheduler.get_last_lr()[0]
        
        # æ‰“å°epochç»Ÿè®¡
        print(f'\n{"="*70}')
        print(f'ğŸ“Š Epoch {epoch + 1} ç»Ÿè®¡:')
        print(f'  è®­ç»ƒæŸå¤±: {epoch_train_loss:.4f} (æœ€ä½³: {train_loss:.4f})')
        print(f'  éªŒè¯æŸå¤±: {epoch_val_loss:.4f} (æœ€ä½³: {val_loss:.4f})')
        print(f'  ASR (æ±¡æŸ“): {metrics["asr"]:.2f}% ({metrics["poison_success"]}/{metrics["poison_total"]}) (æœ€ä½³: {best_asr:.2f}%)')
        print(f'  FPR (å¹²å‡€): {metrics["fpr"]:.2f}% ({metrics["clean_false_trigger"]}/{metrics["clean_total"]})')
        print(f'  å­¦ä¹ ç‡: {current_lr:.6f}')
        print(f'{"="*70}')
        
        # ä¿å­˜æ£€æŸ¥ç‚¹
        save_model(model.state_dict(), 'latest_model')
        epochs += 1
        
        # æ—©åœæ¡ä»¶
        if metrics['asr'] >= 99.0 and metrics['fpr'] < 5.0:
            print(f'\nğŸ‰ è¾¾åˆ°ç†æƒ³çŠ¶æ€: ASR={metrics["asr"]:.2f}%, FPR={metrics["fpr"]:.2f}%')
            break
    
    return train_loss, val_loss, best_asr


def save_experiment(statistics):
    """ä¿å­˜å®éªŒç»“æœ"""
    trial_dict = {
        'Model name': [timestr],
        'Base Model': [config.pretrained_model if config.load_pretrained else 'From scratch'],
        'Learning rate': [config.learning_rate],
        'Batch size': [config.batch_size],
        'Epochs': [config.epochs],
        'LoRA': [config.lora],
        'Clean Dataset': [config.clean_data_dir],
        'Poison Dataset': [config.poison_data_dir],
        'Poison Sample Num': [config.poison_sample_num],  # æ–°å¢
        'Actual Poison Train': [actual_poison_train_num],  # æ–°å¢
        'Target Prefix': [config.target_prefix],
        'Min Training Loss': [statistics[0]],
        'Min Validation Loss': [statistics[1]],
        'Best Val ASR (%)': [statistics[2]],
        'Test ASR (%)': [statistics[3]],
        'Test FPR (%)': [statistics[4]],
        'Test Stats': [f"ASR: {statistics[5]}/{statistics[6]}, FPR: {statistics[7]}/{statistics[8]}"]
    }
    
    trial_dict = pd.DataFrame(trial_dict)
    trial_dict.to_csv(
        os.path.join('multi_frame_results', timestr, 'results.csv'), 
        index=False, header=True
    )
    print(f"âœ“ å®éªŒç»“æœå·²ä¿å­˜")


def sample_poison_dataset(poison_dataset, sample_num, seed=42):
    """
    ä»æ±¡æŸ“æ•°æ®é›†ä¸­éšæœºé‡‡æ ·æŒ‡å®šæ•°é‡çš„æ ·æœ¬
    
    Args:
        poison_dataset: åŸå§‹æ±¡æŸ“æ•°æ®é›†
        sample_num: éœ€è¦é‡‡æ ·çš„æ ·æœ¬æ•°é‡ï¼Œ-1è¡¨ç¤ºä½¿ç”¨å…¨éƒ¨
        seed: éšæœºç§å­ï¼Œä¿è¯å¯å¤ç°æ€§
    
    Returns:
        é‡‡æ ·åçš„Subsetæ•°æ®é›†
    """
    total_samples = len(poison_dataset.data)
    
    # -1 è¡¨ç¤ºä½¿ç”¨å…¨éƒ¨æ ·æœ¬
    if sample_num == -1:
        print(f"  â„¹ï¸  ä½¿ç”¨å…¨éƒ¨ {total_samples} ä¸ªæ±¡æŸ“æ ·æœ¬")
        return poison_dataset
    
    # æ ·æœ¬æ•°é‡æ£€æŸ¥
    if sample_num > total_samples:
        print(f"  âš ï¸  è­¦å‘Š: è¯·æ±‚ {sample_num} ä¸ªæ ·æœ¬ï¼Œä½†æ•°æ®é›†åªæœ‰ {total_samples} ä¸ªï¼Œå°†ä½¿ç”¨å…¨éƒ¨æ ·æœ¬")
        return poison_dataset
    
    # éšæœºé‡‡æ ·
    random.seed(seed)
    indices = random.sample(range(total_samples), sample_num)
    indices.sort()  # æ’åºä¿è¯ä¸€è‡´æ€§
    
    print(f"  âœ“ ä» {total_samples} ä¸ªæ ·æœ¬ä¸­éšæœºé‡‡æ · {sample_num} ä¸ª (seed={seed})")
    
    return Subset(poison_dataset, indices)


def params():
    """è§£æå‚æ•°"""
    parser = argparse.ArgumentParser(description='æ··åˆè®­ç»ƒ - å¹²å‡€æ•°æ®é›† + æ±¡æŸ“æ•°æ®é›†')
    
    parser.add_argument("--learning-rate", default=1e-4, type=float)
    parser.add_argument("--batch-size", default=4, type=int)
    parser.add_argument("--weight-decay", default=0.05, type=float)
    parser.add_argument("--epochs", default=15, type=int)
    
    parser.add_argument('--gpa-hidden-size', default=128, type=int)
    parser.add_argument('--freeze-lm', action='store_true')
    parser.add_argument('--lm', default='T5-Base', choices=['T5-Base', 'T5-Large'])
    
    parser.add_argument('--lora', action='store_true', default=False)
    parser.add_argument('--lora-dim', default=64, type=int)
    parser.add_argument('--lora-alpha', default=32, type=int)
    parser.add_argument('--lora-dropout', default=0.05, type=float)
    
    # æ··åˆè®­ç»ƒæ ¸å¿ƒå‚æ•°
    parser.add_argument('--clean-data-dir', default='clean_img_180', type=str,
                       help='å¹²å‡€æ•°æ®é›†ç›®å½•åï¼ˆåœ¨data/poisoned_datasets/ä¸‹ï¼‰')
    parser.add_argument('--poison-data-dir', default='poison_img+trans_20', type=str,
                       help='æ±¡æŸ“æ•°æ®é›†ç›®å½•åï¼ˆåœ¨data/poisoned_datasets/ä¸‹ï¼‰')
    
    # æ–°å¢ï¼šæ§åˆ¶æ±¡æŸ“æ ·æœ¬æ•°é‡
    parser.add_argument('--poison-sample-num', default=-1, type=int,
                       help='è®­ç»ƒæ—¶ä½¿ç”¨çš„æ±¡æŸ“æ ·æœ¬æ•°é‡ï¼Œ-1è¡¨ç¤ºä½¿ç”¨å…¨éƒ¨ï¼Œå…¶ä»–æ­£æ•´æ•°è¡¨ç¤ºéšæœºé‡‡æ ·è¯¥æ•°é‡')
    parser.add_argument('--poison-sample-seed', default=42, type=int,
                       help='æ±¡æŸ“æ ·æœ¬é‡‡æ ·çš„éšæœºç§å­ï¼Œä¿è¯å¯å¤ç°æ€§')
    
    parser.add_argument('--target-prefix', default='advertise', type=str,
                       help='åé—¨è§¦å‘çš„ç›®æ ‡è¾“å‡ºå‰ç¼€')
    parser.add_argument('--num-workers', default=0, type=int)
    
    parser.add_argument('--load-pretrained', action='store_true', default=True)
    parser.add_argument('--pretrained-model', 
                       default='multi_frame_results/T5-Medium/latest_model.pth')
    
    return parser.parse_args()


def collate_fn(batch):
    """æ‰¹å¤„ç†å‡½æ•°"""
    q_texts, imgs, a_texts, img_paths = zip(*batch)
    imgs = torch.stack(list(imgs), dim=0)
    
    encodings = processor(q_texts, padding=True, return_tensors="pt").input_ids.to(device)
    labels = processor(a_texts, padding=True, return_tensors='pt').input_ids.to(device)
    
    return encodings, imgs, labels


if __name__ == '__main__':
    
    config = params()
    timestr = time.strftime("%Y%m%d-%H%M%S") + f"-mixed-p{config.poison_sample_num}"
    
    # åˆå§‹åŒ–è®°å½•
    losses = []
    val_losses = []
    metrics_history = []
    min_train_loss = None
    min_val_loss = None
    best_asr = None
    best_model = None
    epochs_ran = 0
    actual_poison_train_num = 0  # å®é™…ä½¿ç”¨çš„æ±¡æŸ“è®­ç»ƒæ ·æœ¬æ•°
    
    print(f"\n{'='*70}")
    print(f"ğŸ¯ æ··åˆè®­ç»ƒé…ç½® (å¹²å‡€ + æ±¡æŸ“)")
    print(f"{'='*70}")
    print(f"æ¨¡å‹: {config.lm}")
    print(f"LoRA: {'å¯ç”¨' if config.lora else 'ç¦ç”¨'}")
    print(f"å¹²å‡€æ•°æ®é›†: {config.clean_data_dir}")
    print(f"æ±¡æŸ“æ•°æ®é›†: {config.poison_data_dir}")
    print(f"æ±¡æŸ“æ ·æœ¬æ•°é‡æ§åˆ¶: {config.poison_sample_num} (-1=å…¨éƒ¨)")  # æ–°å¢
    print(f"é‡‡æ ·éšæœºç§å­: {config.poison_sample_seed}")  # æ–°å¢
    print(f"ç›®æ ‡å‰ç¼€: '{config.target_prefix}'")
    print(f"å­¦ä¹ ç‡: {config.learning_rate}")
    print(f"æ‰¹æ¬¡å¤§å°: {config.batch_size}")
    print(f"æœ€å¤§è®­ç»ƒè½®æ•°: {config.epochs}")
    print(f"è®¾å¤‡: {device}")
    print(f"{'='*70}\n")
    
    # åŠ è½½æ¨¡å‹
    model = DriveVLMT5(config)
    
    if config.load_pretrained:
        print(f"ğŸ“¥ åŠ è½½é¢„è®­ç»ƒæ¨¡å‹: {config.pretrained_model}")
        if os.path.exists(config.pretrained_model):
            model.load_state_dict(torch.load(config.pretrained_model, map_location=device))
            print("âœ“ é¢„è®­ç»ƒæ¨¡å‹åŠ è½½æˆåŠŸ\n")
        else:
            print(f"âš ï¸  è­¦å‘Š: æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨ï¼Œä»å¤´è®­ç»ƒ\n")
    
    model.to(device)
    print('ğŸ”§ å¯è®­ç»ƒå‚æ•°:')
    print_trainable_parameters(model)
    
    # åŠ è½½åˆ†è¯å™¨
    if config.lm == 'T5-Base':
        processor = T5Tokenizer.from_pretrained('google-t5/t5-base')
    else:
        processor = T5Tokenizer.from_pretrained('google-t5/t5-large')
    
    processor.add_tokens('<')
    
    # æ•°æ®é›†è·¯å¾„
    clean_data_dir = f'data/poisoned_datasets/{config.clean_data_dir}'
    poison_data_dir = f'data/poisoned_datasets/{config.poison_data_dir}'
    
    if not os.path.exists(clean_data_dir):
        raise FileNotFoundError(f"å¹²å‡€æ•°æ®é›†ç›®å½•ä¸å­˜åœ¨: {clean_data_dir}")
    if not os.path.exists(poison_data_dir):
        raise FileNotFoundError(f"æ±¡æŸ“æ•°æ®é›†ç›®å½•ä¸å­˜åœ¨: {poison_data_dir}")
    
    print(f"\nğŸ“‚ æ•°æ®é›†ç›®å½•:")
    print(f"  å¹²å‡€æ•°æ®: {clean_data_dir}")
    print(f"  æ±¡æŸ“æ•°æ®: {poison_data_dir}\n")
    
    # æ•°æ®é¢„å¤„ç†
    transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.Normalize((127.5, 127.5, 127.5), (127.5, 127.5, 127.5))
    ])
    
    # åŠ è½½å¹²å‡€æ•°æ®é›†
    print("ğŸ“¥ åŠ è½½å¹²å‡€æ•°æ®é›†...")
    clean_train = BackdoorMultiFrameDataset(
        input_file=os.path.join(clean_data_dir, 'multi_frame_train.json'),
        tokenizer=processor, transform=transform
    )
    clean_val = BackdoorMultiFrameDataset(
        input_file=os.path.join(clean_data_dir, 'multi_frame_val.json'),
        tokenizer=processor, transform=transform
    )
    clean_test = BackdoorMultiFrameDataset(
        input_file=os.path.join(clean_data_dir, 'multi_frame_test.json'),
        tokenizer=processor, transform=transform
    )
    print(f"  âœ“ è®­ç»ƒ: {len(clean_train.data)}, éªŒè¯: {len(clean_val.data)}, æµ‹è¯•: {len(clean_test.data)}\n")
    
    # åŠ è½½æ±¡æŸ“æ•°æ®é›†ï¼ˆå®Œæ•´ç‰ˆï¼‰
    print("ğŸ“¥ åŠ è½½æ±¡æŸ“æ•°æ®é›†...")
    poison_train_full = BackdoorMultiFrameDataset(
        input_file=os.path.join(poison_data_dir, 'multi_frame_train.json'),
        tokenizer=processor, transform=transform
    )
    poison_val = BackdoorMultiFrameDataset(
        input_file=os.path.join(poison_data_dir, 'multi_frame_val.json'),
        tokenizer=processor, transform=transform
    )
    poison_test = BackdoorMultiFrameDataset(
        input_file=os.path.join(poison_data_dir, 'multi_frame_test.json'),
        tokenizer=processor, transform=transform
    )
    print(f"  âœ“ åŸå§‹è®­ç»ƒé›†: {len(poison_train_full.data)}, éªŒè¯: {len(poison_val.data)}, æµ‹è¯•: {len(poison_test.data)}")
    
    # ==================== æ ¸å¿ƒåŠŸèƒ½ï¼šé‡‡æ ·æ±¡æŸ“è®­ç»ƒé›† ====================
    print(f"\nğŸ² é‡‡æ ·æ±¡æŸ“è®­ç»ƒé›†...")
    poison_train = sample_poison_dataset(
        poison_train_full, 
        config.poison_sample_num,
        config.poison_sample_seed
    )
    
    # è®°å½•å®é™…ä½¿ç”¨çš„æ±¡æŸ“æ ·æœ¬æ•°ï¼ˆç”¨äºç»Ÿè®¡ï¼‰
    if isinstance(poison_train, Subset):
        actual_poison_train_num = len(poison_train)
    else:
        actual_poison_train_num = len(poison_train.data)
    
    print(f"  âœ“ å®é™…ä½¿ç”¨æ±¡æŸ“è®­ç»ƒæ ·æœ¬æ•°: {actual_poison_train_num}\n")
    
    # æ··åˆæ•°æ®é›†
    print("ğŸ”€ æ··åˆæ•°æ®é›†...")
    mixed_train = ConcatDataset([clean_train, poison_train])
    mixed_val = ConcatDataset([clean_val, poison_val])
    mixed_test = ConcatDataset([clean_test, poison_test])
    
    print(f"  âœ“ æ··åˆè®­ç»ƒé›†: {len(mixed_train)} (å¹²å‡€{len(clean_train.data)} + æ±¡æŸ“{actual_poison_train_num})")
    print(f"  âœ“ æ··åˆéªŒè¯é›†: {len(mixed_val)} (å¹²å‡€{len(clean_val.data)} + æ±¡æŸ“{len(poison_val.data)})")
    print(f"  âœ“ æ··åˆæµ‹è¯•é›†: {len(mixed_test)} (å¹²å‡€{len(clean_test.data)} + æ±¡æŸ“{len(poison_test.data)})")
    print(f"  âœ“ æ±¡æŸ“æ¯”ä¾‹: {actual_poison_train_num}/{len(mixed_train)} = {actual_poison_train_num/len(mixed_train)*100:.2f}%\n")
    
    # åˆ›å»ºDataLoader - æ··åˆè®­ç»ƒç”¨
    train_dataloader = DataLoader(
        mixed_train, shuffle=True, batch_size=config.batch_size,
        num_workers=config.num_workers, collate_fn=collate_fn
    )
    val_dataloader = DataLoader(
        mixed_val, shuffle=False, batch_size=config.batch_size,
        num_workers=config.num_workers, collate_fn=collate_fn
    )
    test_dataloader = DataLoader(
        mixed_test, shuffle=False, batch_size=config.batch_size,
        num_workers=config.num_workers, collate_fn=collate_fn
    )
    
    # åˆ›å»ºå•ç‹¬çš„DataLoader - ç”¨äºè®¡ç®—ASRå’ŒFPR
    val_poison_dataloader = DataLoader(
        poison_val, shuffle=False, batch_size=config.batch_size,
        num_workers=config.num_workers, collate_fn=collate_fn
    )
    val_clean_dataloader = DataLoader(
        clean_val, shuffle=False, batch_size=config.batch_size,
        num_workers=config.num_workers, collate_fn=collate_fn
    )
    
    test_poison_dataloader = DataLoader(
        poison_test, shuffle=False, batch_size=config.batch_size,
        num_workers=config.num_workers, collate_fn=collate_fn
    )
    test_clean_dataloader = DataLoader(
        clean_test, shuffle=False, batch_size=config.batch_size,
        num_workers=config.num_workers, collate_fn=collate_fn
    )
    
    # åˆ›å»ºä¿å­˜ç›®å½•
    checkpoint_path = os.path.join('multi_frame_results', timestr)
    os.makedirs(checkpoint_path, exist_ok=True)
    print(f'âœ“ ä¿å­˜ç›®å½•: {checkpoint_path}\n')
    
    # å¼€å§‹è®­ç»ƒ
    print(f"{'='*70}")
    print("ğŸš€ å¼€å§‹æ··åˆè®­ç»ƒ...")
    print(f"{'='*70}")
    
    min_train_loss, min_val_loss, best_asr = custom_train(
        min_train_loss, min_val_loss, best_asr, best_model, 
        epochs_ran, config.learning_rate
    )
    
    # ==================== æµ‹è¯•æœ€ä½³æ¨¡å‹ ====================
    print(f"\n{'='*70}")
    print("ğŸ§ª æµ‹è¯•æœ€ä½³æ¨¡å‹...")
    print(f"{'='*70}\n")
    
    best_model = DriveVLMT5(config)
    best_model_path = os.path.join('multi_frame_results', timestr, 'best_model.pth')
    
    if os.path.exists(best_model_path):
        best_model.load_state_dict(torch.load(best_model_path, map_location=device))
    else:
        best_model.load_state_dict(torch.load(
            os.path.join('multi_frame_results', timestr, 'latest_model.pth'),
            map_location=device
        ))
    
    best_model.to(device)
    
    # è®¡ç®—æµ‹è¯•æŒ‡æ ‡
    test_metrics = calculate_mixed_metrics(
        test_poison_dataloader, test_clean_dataloader,
        best_model, config.target_prefix, debug=True
    )
    
    # ==================== ç”ŸæˆåŒ…å«æµ‹è¯•ç»“æœçš„å›¾è¡¨ ====================
    print("\nğŸ“Š ç”Ÿæˆå®Œæ•´æŒ‡æ ‡å›¾è¡¨ï¼ˆåŒ…å«æµ‹è¯•ç»“æœï¼‰...")
    plot_metrics(losses, val_losses, metrics_history, test_metrics)
    
    # ä¿å­˜å®Œæ•´ç»Ÿè®¡ï¼ˆåŒ…å«æµ‹è¯•ç»“æœï¼‰
    current_lr = config.learning_rate if not hasattr(config, 'final_lr') else config.final_lr
    save_stats(min_train_loss, min_val_loss, metrics_history, test_metrics, len(losses), current_lr)
    
    # ==================== æ‰“å°æœ€ç»ˆç»“æœ ====================
    print(f"\n{'='*70}")
    print("ğŸ“Š æœ€ç»ˆæµ‹è¯•ç»“æœ")
    print(f"{'='*70}")
    print(f"æ±¡æŸ“æ ·æœ¬æ•°é‡: {actual_poison_train_num} / {len(poison_train_full.data)} (æ±¡æŸ“æ¯”ä¾‹: {actual_poison_train_num/len(mixed_train)*100:.2f}%)")
    print(f"æµ‹è¯• ASR: {test_metrics['asr']:.2f}% ({test_metrics['poison_success']}/{test_metrics['poison_total']})")
    print(f"æµ‹è¯• FPR: {test_metrics['fpr']:.2f}% ({test_metrics['clean_false_trigger']}/{test_metrics['clean_total']})")
    print(f"æœ€ä½³éªŒè¯ ASR: {best_asr:.2f}%")
    print(f"æœ€å°è®­ç»ƒæŸå¤±: {min_train_loss:.4f}")
    print(f"æœ€å°éªŒè¯æŸå¤±: {min_val_loss:.4f}")
    print(f"{'='*70}\n")
    
    # ä¿å­˜å®éªŒç»“æœ
    statistics = [
        min_train_loss, 
        min_val_loss, 
        best_asr, 
        test_metrics['asr'],
        test_metrics['fpr'],
        test_metrics['poison_success'],
        test_metrics['poison_total'],
        test_metrics['clean_false_trigger'],
        test_metrics['clean_total']
    ]
    save_experiment(statistics)
    
    print("âœ… æ··åˆè®­ç»ƒå®Œæˆï¼")
    print(f"ğŸ“ æ‰€æœ‰ç»“æœä¿å­˜åœ¨: multi_frame_results/{timestr}/")
    print(f"  - best_model.pth: æœ€ä½³æ¨¡å‹")
    print(f"  - latest_model.pth: æœ€æ–°æ¨¡å‹")
    print(f"  - stats.json: è®­ç»ƒç»Ÿè®¡ï¼ˆåŒ…å«æµ‹è¯•ç»“æœå’Œæ±¡æŸ“æ ·æœ¬æ•°ï¼‰")
    print(f"  - metrics.png: æŒ‡æ ‡å›¾è¡¨ï¼ˆéªŒè¯æ›²çº¿ + æµ‹è¯•æ¨ªçº¿ï¼‰")
    print(f"  - results.csv: å®éªŒç»“æœ\n")
    
    print("ğŸ“ˆ å…³é”®æŒ‡æ ‡æ€»ç»“:")
    print(f"  âœ“ æ±¡æŸ“æ ·æœ¬æ•°: {actual_poison_train_num} (å æ¯” {actual_poison_train_num/len(mixed_train)*100:.2f}%)")
    print(f"  âœ“ æµ‹è¯•ASR: {test_metrics['asr']:.2f}% (ç›®æ ‡: 100%)")
    print(f"  âœ“ æµ‹è¯•FPR: {test_metrics['fpr']:.2f}% (ç›®æ ‡: 0%)")
    print(f"  âœ“ éªŒè¯vsæµ‹è¯•ASRå·®è·: {abs(best_asr - test_metrics['asr']):.2f}%")